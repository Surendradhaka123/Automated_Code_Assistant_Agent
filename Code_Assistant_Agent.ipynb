{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Code Assistant Agent Design Overview\n",
        "\n",
        "Architecture and Approach:\n",
        "This code assistant agent is designed using a graph-based architecture with LangGraph to create a robust,\n",
        "iterative code generation and validation system. The agent uses Mistral's large language model for code\n",
        "generation and implements a self-correcting mechanism through multiple attempts.\n",
        "\n",
        "Key Components:\n",
        "1. State Management: Uses GraphState to track conversation history, code generations, error states, and\n",
        "   iteration counts.\n",
        "2. Code Generation: Structured output generation using Pydantic models to ensure consistent code formatting\n",
        "   with imports, main code, and descriptions.\n",
        "3. Validation Pipeline: Two-stage validation checking both imports and code execution separately to provide\n",
        "   specific feedback.\n",
        "4. Output Capture: Implements stdout redirection to capture both code execution results and print statements.\n",
        "5. Efficient memory Management by keeping the original user question, most recent and relevant context.\n",
        "\n",
        "Design Assumptions:\n",
        "- Code solutions should be self-contained and executable\n",
        "- Maximum 3 iterations for self-correction to prevent infinite loops\n",
        "- User questions will be primarily focused on Python programming tasks\n",
        "- Code solutions should include necessary imports and complete implementation\n",
        "\n",
        "Potential Improvements:\n",
        "1. Enhanced Error Handling:\n",
        "   - Add more granular error categorization\n",
        "   - Implement specific strategies for different types of errors\n",
        "   - Add syntax validation before execution\n",
        "\n",
        "2. Safety and Security:\n",
        "   - Implement sandboxed code execution\n",
        "   - Add timeout mechanisms for long-running code\n",
        "   - Add input validation and code sanitization\n",
        "\n",
        "3. Expanded Capabilities:\n",
        "   - Support for multiple programming languages\n",
        "   - Add unit test generation\n",
        "   - Add memory of previous successful solutions\n",
        "\n",
        "4. User Experience:\n",
        "   - Add progress indicators for long-running operations\n",
        "   - Implement interactive debugging\n",
        "   - Add code complexity analysis\n",
        "\n",
        "5. Performance:\n",
        "   - Implement caching for common solutions\n",
        "   - Add parallel validation checks\n",
        "   - Optimize model prompting for faster responses\n",
        "\n",
        "This implementation focuses on creating a reliable foundation for code generation with\n",
        "built-in validation and self-correction capabilities, while maintaining extensibility for future improvements."
      ],
      "metadata": {
        "id": "3aIW8HTdHBUe"
      },
      "id": "3aIW8HTdHBUe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e501686f-323f-4b87-8f9c-8ba89133078b",
      "metadata": {
        "id": "e501686f-323f-4b87-8f9c-8ba89133078b"
      },
      "outputs": [],
      "source": [
        "! pip install -U langchain_community langchain-mistralai langchain langgraph"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "so3F0VqlWxYR",
        "outputId": "5215f92d-193f-478a-c2d2-ab62012b9ded"
      },
      "id": "so3F0VqlWxYR",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ef4fb67-113a-4b88-9f93-7e3a95cee035",
      "metadata": {
        "id": "9ef4fb67-113a-4b88-9f93-7e3a95cee035"
      },
      "source": [
        "### LLM\n",
        "\n",
        "We'll use the Mistral API and mistral-large-latest model, which support tool use!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "982e4609-86e4-4934-828f-e03d89c20393",
      "metadata": {
        "id": "982e4609-86e4-4934-828f-e03d89c20393"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
        "mistral_api_key = os.getenv(\"MISTRAL_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3a3dca9-4485-4ae5-aa87-cd1f02bad8b9",
      "metadata": {
        "id": "d3a3dca9-4485-4ae5-aa87-cd1f02bad8b9"
      },
      "source": [
        "## Code Generation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a188c8ca-c053-4e6d-b7af-38a3b6b371c7",
      "metadata": {
        "id": "a188c8ca-c053-4e6d-b7af-38a3b6b371c7"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langchain_mistralai import ChatMistralAI\n",
        "\n",
        "mistral_model = \"mistral-large-latest\"\n",
        "llm = ChatMistralAI(model=mistral_model, temperature=0)\n",
        "\n",
        "# Prompt\n",
        "code_gen_prompt_claude = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"\"\"You are a coding assistant. Ensure any code you provide can be executed with all required imports and variables \\n\n",
        "            defined. Structure your answer: 1) a prefix describing the code solution, 2) the imports, 3) the functioning code block.\n",
        "            \\n Here is the user question:\"\"\",\n",
        "        ),\n",
        "        (\"placeholder\", \"{messages}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "# Data model\n",
        "class code(BaseModel):\n",
        "    \"\"\"Code output\"\"\"\n",
        "\n",
        "    prefix: str = Field(description=\"Description of the problem and approach\")\n",
        "    imports: str = Field(description=\"Code block import statements\")\n",
        "    code: str = Field(description=\"Code block not including import statements\")\n",
        "    description = \"Schema for code solutions to answer users questions\"\n",
        "\n",
        "\n",
        "code_gen_chain = llm.with_structured_output(code, include_raw=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4235eb2d-f5b3-4cd0-bbb1-a889eb5564d7",
      "metadata": {
        "id": "4235eb2d-f5b3-4cd0-bbb1-a889eb5564d7"
      },
      "source": [
        "## State"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "183d77b8-f180-4815-b39f-8ef507ec0534",
      "metadata": {
        "id": "183d77b8-f180-4815-b39f-8ef507ec0534"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated, TypedDict\n",
        "\n",
        "from langgraph.graph.message import AnyMessage, add_messages\n",
        "\n",
        "\n",
        "class GraphState(TypedDict):\n",
        "    \"\"\"\n",
        "    Represents the state of our graph.\n",
        "\n",
        "    Attributes:\n",
        "        error : Binary flag for control flow to indicate whether test error was tripped\n",
        "        messages : With user question, error messages, reasoning\n",
        "        generation : Code solution\n",
        "        iterations : Number of tries\n",
        "    \"\"\"\n",
        "\n",
        "    error: str\n",
        "    messages: Annotated[list[AnyMessage], add_messages]\n",
        "    generation: str\n",
        "    iterations: int"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55043d78-c012-4280-bc8b-259f04a29cb4",
      "metadata": {
        "id": "55043d78-c012-4280-bc8b-259f04a29cb4"
      },
      "source": [
        "## Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "14bc89d1-3ca6-4847-a048-1803e0e4600e",
      "metadata": {
        "id": "14bc89d1-3ca6-4847-a048-1803e0e4600e"
      },
      "outputs": [],
      "source": [
        "import uuid\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "\n",
        "max_iterations = 3 #number of retry\n",
        "\n",
        "\n",
        "# Nodes\n",
        "def generate(state: GraphState):\n",
        "    \"\"\"\n",
        "    Generate a code solution\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): New key added to state, generation\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---GENERATING CODE SOLUTION---\")\n",
        "\n",
        "    # State\n",
        "    messages = state[\"messages\"]\n",
        "    iterations = state[\"iterations\"]\n",
        "\n",
        "    code_solution = code_gen_chain.invoke(messages)\n",
        "    messages += [\n",
        "        (\n",
        "            \"assistant\",\n",
        "            f\"Here is my attempt to solve the problem: {code_solution.prefix} \\n Imports: {code_solution.imports} \\n Code: {code_solution.code}\",\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    iterations = iterations + 1\n",
        "    return {\"generation\": code_solution, \"messages\": messages, \"iterations\": iterations}\n",
        "\n",
        "\n",
        "def code_check(state: GraphState):\n",
        "    \"\"\"\n",
        "    Check code\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): New key added to state, error\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---CHECKING CODE---\")\n",
        "\n",
        "    # State\n",
        "    messages = state[\"messages\"]\n",
        "    code_solution = state[\"generation\"]\n",
        "    iterations = state[\"iterations\"]\n",
        "\n",
        "    # Keeping only the original user input and last 3 responses if messages exceed this limit\n",
        "    if len(messages) > 7:  # 7 = 1 user input + 3 pairs of (assistant response + error message)\n",
        "        # original user input\n",
        "        original_input = messages[0]\n",
        "\n",
        "        # Get the last 6 messages\n",
        "        last_messages = messages[-6:]\n",
        "\n",
        "        # Reconstructing messages with original input + last messages\n",
        "        messages = [original_input] + last_messages\n",
        "        print(\"---TRIMMED MESSAGE HISTORY---\")\n",
        "\n",
        "    imports = code_solution.imports\n",
        "    code = code_solution.code\n",
        "\n",
        "    # Check imports\n",
        "    try:\n",
        "        exec(imports)\n",
        "    except Exception as e:\n",
        "        print(\"---CODE IMPORT CHECK: FAILED---\")\n",
        "        error_message = [\n",
        "            (\n",
        "                \"user\",\n",
        "                f\"Your solution failed the import test. Here is the error: {e}. Reflect on this error and your prior attempt to solve the problem. (1) State what you think went wrong with the prior solution and (2) try to solve this problem again. Return the FULL SOLUTION. Use the code tool to structure the output with a prefix, imports, and code block:\",\n",
        "            )\n",
        "        ]\n",
        "        messages += error_message\n",
        "        return {\n",
        "            \"generation\": code_solution,\n",
        "            \"messages\": messages,\n",
        "            \"iterations\": iterations,\n",
        "            \"error\": \"yes\",\n",
        "        }\n",
        "\n",
        "    # Check execution\n",
        "    try:\n",
        "        combined_code = f\"{imports}\\n{code}\"\n",
        "        print(f\"CODE TO TEST: {combined_code}\")\n",
        "\n",
        "        #shared scope for exec\n",
        "        global_scope = {}\n",
        "        exec(combined_code, global_scope)\n",
        "    except Exception as e:\n",
        "        print(\"---CODE BLOCK CHECK: FAILED---\")\n",
        "        error_message = [\n",
        "            (\n",
        "                \"user\",\n",
        "                f\"Your solution failed the code execution test: {e}) Reflect on this error and your prior attempt to solve the problem. (1) State what you think went wrong with the prior solution and (2) try to solve this problem again. Return the FULL SOLUTION. Use the code tool to structure the output with a prefix, imports, and code block:\",\n",
        "            )\n",
        "        ]\n",
        "        messages += error_message\n",
        "        return {\n",
        "            \"generation\": code_solution,\n",
        "            \"messages\": messages,\n",
        "            \"iterations\": iterations,\n",
        "            \"error\": \"yes\",\n",
        "        }\n",
        "\n",
        "    # No errors\n",
        "    final_message = [\n",
        "            (\n",
        "                \"user\",\n",
        "                f\"Above is my final attempt to solve the problem, generate the final response with description of the problem and above final approach. Don't mentation any above errors which we got earlier.\",\n",
        "            )\n",
        "        ]\n",
        "    messages += final_message\n",
        "    print(\"---NO CODE TEST FAILURES---\")\n",
        "    return {\n",
        "        \"generation\": code_solution,\n",
        "        \"messages\": messages,\n",
        "        \"iterations\": iterations,\n",
        "        \"error\": \"no\",\n",
        "    }\n",
        "\n",
        "### Conditional edges\n",
        "\n",
        "def decide_to_finish(state: GraphState):\n",
        "    \"\"\"\n",
        "    Determines whether to finish.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        str: Next node to call\n",
        "    \"\"\"\n",
        "    error = state[\"error\"]\n",
        "    iterations = state[\"iterations\"]\n",
        "\n",
        "    if error == \"no\" or iterations == max_iterations:\n",
        "        print(\"---DECISION: FINISH---\")\n",
        "        return \"generate_final_response\"\n",
        "    else:\n",
        "        print(\"---DECISION: RE-TRY SOLUTION---\")\n",
        "        return \"generate\"\n",
        "\n",
        "\n",
        "def _print_event(event: dict, _printed: set, max_length=1500):\n",
        "    current_state = event.get(\"dialog_state\")\n",
        "    if current_state:\n",
        "        print(\"Currently in: \", current_state[-1])\n",
        "    message = event.get(\"messages\")\n",
        "    if message:\n",
        "        if isinstance(message, list):\n",
        "            message = message[-1]\n",
        "        if message.id not in _printed:\n",
        "            msg_repr = message.pretty_repr(html=True)\n",
        "            if len(msg_repr) > max_length:\n",
        "                msg_repr = msg_repr[:max_length] + \" ... (truncated)\"\n",
        "            print(msg_repr)\n",
        "            _printed.add(message.id)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "from io import StringIO\n",
        "from contextlib import redirect_stdout\n",
        "\n",
        "def generate_final_response(state: GraphState):\n",
        "    \"\"\"\n",
        "    Generate a code solution\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): New key added to state, error\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---GENERATING FINAL RESPONSE---\")\n",
        "\n",
        "    # State\n",
        "    messages = state[\"messages\"]\n",
        "    iterations = state[\"iterations\"]\n",
        "\n",
        "\n",
        "    code_solution = code_gen_chain.invoke(messages)\n",
        "\n",
        "    imports = code_solution.imports\n",
        "    code = code_solution.code\n",
        "\n",
        "    # Buffer to capture output\n",
        "    output_buffer = StringIO()\n",
        "\n",
        "    try:\n",
        "        with redirect_stdout(output_buffer):\n",
        "            combined_code = f\"{imports}\\n{code}\"\n",
        "            global_scope = {}\n",
        "            exec(combined_code, global_scope)\n",
        "\n",
        "        # Get the captured output\n",
        "        result = output_buffer.getvalue()\n",
        "        if not result:\n",
        "            result = \"Code executed successfully but produced no output\"\n",
        "\n",
        "    except Exception as e:\n",
        "        result = f\"Error occurred: {str(e)}\"\n",
        "\n",
        "    finally:\n",
        "        output_buffer.close()\n",
        "\n",
        "    messages += [\n",
        "        (\n",
        "            \"assistant\",\n",
        "            f\"{code_solution.prefix} \\n\"\n",
        "            f\"{code_solution.imports} \\n\"\n",
        "            f\"Code: {code_solution.code} \\n\\n\"\n",
        "            f\"Test output: {result}\",\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    return {\n",
        "        \"generation\": code_solution,\n",
        "        \"messages\": messages,\n",
        "        \"iterations\": iterations,\n",
        "        \"error\": \"no\",\n",
        "    }"
      ],
      "metadata": {
        "id": "VxRjl-xVeOHj"
      },
      "id": "VxRjl-xVeOHj",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "2dff2209-44c7-4e2c-b607-ba6675f9e45f",
      "metadata": {
        "id": "2dff2209-44c7-4e2c-b607-ba6675f9e45f"
      },
      "outputs": [],
      "source": [
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.graph import END, StateGraph, START\n",
        "\n",
        "builder = StateGraph(GraphState)\n",
        "\n",
        "# Define the nodes\n",
        "builder.add_node(\"generate\", generate)  # generation solution\n",
        "builder.add_node(\"check_code\", code_check)  # check code\n",
        "builder.add_node(\"generate_final_response\", generate_final_response) #generate_final_response\n",
        "\n",
        "# Build graph\n",
        "builder.add_edge(START, \"generate\")\n",
        "builder.add_edge(\"generate\", \"check_code\")\n",
        "builder.add_conditional_edges(\n",
        "    \"check_code\",\n",
        "    decide_to_finish,\n",
        "    {\n",
        "        \"generate_final_response\": \"generate_final_response\",\n",
        "        \"generate\": \"generate\",\n",
        "    },\n",
        ")\n",
        "builder.add_edge(\"generate_final_response\", END)\n",
        "\n",
        "memory = MemorySaver()\n",
        "graph = builder.compile(checkpointer=memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "d4bb21cd-af20-4d4d-89ff-384db034b7c3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "d4bb21cd-af20-4d4d-89ff-384db034b7c3",
        "outputId": "446692c2-07d7-423d-c1e8-7e59c2ae6992"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n",
        "except Exception:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "thread_id = str(uuid.uuid4())\n",
        "config = {\n",
        "    \"configurable\": {\n",
        "        \"thread_id\": thread_id,\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "ePs18_jxZy44"
      },
      "id": "ePs18_jxZy44",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ask():\n",
        "  while True:\n",
        "    question=input(\"Ask a question or write exit to quit! : \")\n",
        "    if question.lower() == \"exit\":\n",
        "      break\n",
        "    resp = graph.invoke({\"messages\": [(\"user\", question)], \"iterations\": 3}, config)\n",
        "    print(f\"\\n \\n\")\n",
        "    print(resp['messages'][-1].content)"
      ],
      "metadata": {
        "id": "N8jHMY7-c6Rj"
      },
      "id": "N8jHMY7-c6Rj",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dRHj2v12DXF9"
      },
      "id": "dRHj2v12DXF9",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ask()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfzJ7TRowU1H",
        "outputId": "85eb9e51-aff7-4abc-97cb-2b834fee8e43"
      },
      "id": "QfzJ7TRowU1H",
      "execution_count": 26,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ask a question or write exit to quit! : write the code to check if word MADAM is palindrome or not\n",
            "---GENERATING CODE SOLUTION---\n",
            "---CHECKING CODE---\n",
            "CODE TO TEST: \n",
            "def is_palindrome(word):\n",
            "    # Remove any spaces and convert to lowercase\n",
            "    word = word.replace(\" \", \"\").lower()\n",
            "    # Check if the word is equal to its reverse\n",
            "    return word == word[::-1]\n",
            "\n",
            "# Test the function with the word 'MADAM'\n",
            "word = 'MADAM'\n",
            "if is_palindrome(word):\n",
            "    print(f'The word {word} is a palindrome.')\n",
            "else:\n",
            "    print(f'The word {word} is not a palindrome.')\n",
            "The word MADAM is a palindrome.\n",
            "---NO CODE TEST FAILURES---\n",
            "---DECISION: FINISH---\n",
            "---GENERATING FINAL RESPONSE---\n",
            "\n",
            " \n",
            "\n",
            "To determine if the word 'MADAM' is a palindrome, we need to check if it reads the same backward as forward. Here's a step-by-step approach to solve this problem: \n",
            " \n",
            "Code: def is_palindrome(word):\n",
            "    # Remove any spaces and convert to lowercase\n",
            "    word = word.replace(\" \", \"\").lower()\n",
            "    # Check if the word is equal to its reverse\n",
            "    return word == word[::-1]\n",
            "\n",
            "# Test the function with the word 'MADAM'\n",
            "word = 'MADAM'\n",
            "if is_palindrome(word):\n",
            "    print(f'The word {word} is a palindrome.')\n",
            "else:\n",
            "    print(f'The word {word} is not a palindrome.') \n",
            "Test output: The word MADAM is a palindrome.\n",
            "\n",
            "Ask a question or write exit to quit! : what about Teacher ?\n",
            "---GENERATING CODE SOLUTION---\n",
            "---CHECKING CODE---\n",
            "CODE TO TEST: \n",
            "def is_palindrome(word):\n",
            "    # Remove any spaces and convert to lowercase\n",
            "    word = word.replace(\" \", \"\").lower()\n",
            "    # Check if the word is equal to its reverse\n",
            "    return word == word[::-1]\n",
            "\n",
            "# Test the function with the word 'Teacher'\n",
            "word = 'Teacher'\n",
            "if is_palindrome(word):\n",
            "    print(f'The word {word} is a palindrome.')\n",
            "else:\n",
            "    print(f'The word {word} is not a palindrome.')\n",
            "The word Teacher is not a palindrome.\n",
            "---NO CODE TEST FAILURES---\n",
            "---DECISION: FINISH---\n",
            "---GENERATING FINAL RESPONSE---\n",
            "\n",
            " \n",
            "\n",
            "To determine if the word 'Teacher' is a palindrome, we need to check if it reads the same backward as forward. Here's a step-by-step approach to solve this problem: \n",
            " \n",
            "Code: def is_palindrome(word):\n",
            "    # Remove any spaces and convert to lowercase\n",
            "    word = word.replace(\" \", \"\").lower()\n",
            "    # Check if the word is equal to its reverse\n",
            "    return word == word[::-1]\n",
            "\n",
            "# Test the function with the word 'Teacher'\n",
            "word = 'Teacher'\n",
            "if is_palindrome(word):\n",
            "    print(f'The word {word} is a palindrome.')\n",
            "else:\n",
            "    print(f'The word {word} is not a palindrome.') \n",
            "Test output: The word Teacher is not a palindrome.\n",
            "\n",
            "Ask a question or write exit to quit! : exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "92h6LSvtGejq"
      },
      "id": "92h6LSvtGejq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ask()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbBSdNqdF_7S",
        "outputId": "06a8381d-178f-427f-84d3-8a0abca891ac"
      },
      "id": "qbBSdNqdF_7S",
      "execution_count": 29,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ask a question or write exit to quit! : \"Find the user with the highest total transaction amount from the CSV\n",
            "---GENERATING CODE SOLUTION---\n",
            "---CHECKING CODE---\n",
            "CODE TO TEST: import pandas as pd\n",
            "def find_highest_transaction_user(csv_file):\n",
            "    # Read the CSV file into a DataFrame\n",
            "    df = pd.read_csv(csv_file)\n",
            "    \n",
            "    # Group by user and sum the transaction amounts\n",
            "    user_totals = df.groupby('user_id')['transaction_amount'].sum()\n",
            "    \n",
            "    # Find the user with the highest total transaction amount\n",
            "    highest_transaction_user = user_totals.idxmax()\n",
            "    highest_transaction_amount = user_totals.max()\n",
            "    \n",
            "    return highest_transaction_user, highest_transaction_amount\n",
            "\n",
            "# Example usage\n",
            "csv_file = 'transactions.csv'\n",
            "user, amount = find_highest_transaction_user(csv_file)\n",
            "print(f'The user with the highest total transaction amount is User ID: {user} with a total amount of: {amount}')\n",
            "---CODE BLOCK CHECK: FAILED---\n",
            "---DECISION: RE-TRY SOLUTION---\n",
            "---GENERATING CODE SOLUTION---\n",
            "---CHECKING CODE---\n",
            "CODE TO TEST: import pandas as pd\n",
            "from io import StringIO\n",
            "def find_highest_transaction_user(csv_data):\n",
            "    # Read the CSV data into a DataFrame\n",
            "    df = pd.read_csv(StringIO(csv_data))\n",
            "    \n",
            "    # Group by user and sum the transaction amounts\n",
            "    user_totals = df.groupby('user_id')['transaction_amount'].sum()\n",
            "    \n",
            "    # Find the user with the highest total transaction amount\n",
            "    highest_transaction_user = user_totals.idxmax()\n",
            "    highest_transaction_amount = user_totals.max()\n",
            "    \n",
            "    return highest_transaction_user, highest_transaction_amount\n",
            "\n",
            "# Sample CSV data\n",
            "csv_data = '''\\\n",
            "user_id,transaction_amount\n",
            "1,100\n",
            "2,200\n",
            "1,300\n",
            "3,150\n",
            "2,250\n",
            "'''\n",
            "\n",
            "# Example usage\n",
            "user, amount = find_highest_transaction_user(csv_data)\n",
            "print(f'The user with the highest total transaction amount is User ID: {user} with a total amount of: {amount}')\n",
            "The user with the highest total transaction amount is User ID: 2 with a total amount of: 450\n",
            "---NO CODE TEST FAILURES---\n",
            "---DECISION: FINISH---\n",
            "---GENERATING FINAL RESPONSE---\n",
            "\n",
            " \n",
            "\n",
            "To find the user with the highest total transaction amount from a CSV file, we can follow these steps:\n",
            "\n",
            "1. Read the CSV data into a DataFrame.\n",
            "2. Group the data by the user identifier.\n",
            "3. Sum the transaction amounts for each user.\n",
            "4. Identify the user with the highest total transaction amount.\n",
            "\n",
            "Here is the Python code to achieve this: \n",
            "import pandas as pd\n",
            "from io import StringIO \n",
            "Code: def find_highest_transaction_user(csv_data):\n",
            "    # Read the CSV data into a DataFrame\n",
            "    df = pd.read_csv(StringIO(csv_data))\n",
            "    \n",
            "    # Group by user and sum the transaction amounts\n",
            "    user_totals = df.groupby('user_id')['transaction_amount'].sum()\n",
            "    \n",
            "    # Find the user with the highest total transaction amount\n",
            "    highest_transaction_user = user_totals.idxmax()\n",
            "    highest_transaction_amount = user_totals.max()\n",
            "    \n",
            "    return highest_transaction_user, highest_transaction_amount\n",
            "\n",
            "# Sample CSV data\n",
            "csv_data = '''\\\n",
            "user_id,transaction_amount\\\n",
            "1,100\\\n",
            "2,200\\\n",
            "1,300\\\n",
            "3,150\\\n",
            "2,250\\\n",
            "'''\n",
            "\n",
            "# Example usage\n",
            "user, amount = find_highest_transaction_user(csv_data)\n",
            "print(f'The user with the highest total transaction amount is User ID: {user} with a total amount of: {amount}') \n",
            "Test output: Error occurred: 'Column not found: transaction_amount'\n",
            "Ask a question or write exit to quit! : exit\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}